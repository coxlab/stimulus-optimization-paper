% Please keep the abstract between 250 and 300 words

A central challenge in sensory neuroscience is describing how the activity of populations of neurons can ``represent'' useful features of the external environment.
However, while neurophysiologists have long been able to record the responses of neurons in awake, behaving animals, it is another matter entirely to say what a given neuron ``does.''
A key problem is that in many sensory domains, the space of all possible stimuli that one might encounter is effectively infinite; in vision, for instance, natural scenes are combinatorally complex, and an organism will only encounter a tiny fraction of possible stimuli.
As a result, even describing the response properties of sensory neurons in difficult, and investigations of neuronal function are almost always critically limited by the number of stimuli that can be considered.

Here, we propose a closed-loop, optimization-based experimental framework for characterizing the response properties of sensory neurons, building on past efforts in closed-loop experimental methods, and leveraging recent advances in artificial neural network models to serve as as a proving ground for our techniques.
Using ``deep'' convolutional neural networks as a proving ground, we asked whether modern black-box optimization techniques can be used to interrogate the response landscape of an artificial neuron in a deep, nonlinear system, without imposing significant constraints on the space of stimuli under consideration.
We introduce a series metrics to quantify neuronal response landscapes, and show how these relate to the performance of the network in an object recognition task.
To the extent that deep learning models increasingly serve as \emph{de facto} working hypotheses for biological vision \ref{jim, others}, we argue that developing a unified approach for studying both natural and artifical systems holds great potential to advance both fields together.