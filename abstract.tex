% Please keep the abstract between 250 and 300 words

A central challenge in sensory neuroscience is to describe how the activity in populations of neurons represents properties of the external environment in a format suitable for guiding behavior.
However, while neurophysiologists have long been able to record the responses of neurons in awake, behaving animals, it is another matter entirely to say what a given neuron ``does.''
A key problem is that in many sensory systems, the space of all possible stimuli that one might encounter is effectively infinite.  For instance, in vision, scenes are combinatorially complex---an individual human will encounter only a small fraction of the possible scenes in the world; indeed only a small fraction of the possible images have \emph{ever} been experienced in the collective history of the human race.
Thus, investigations of neuronal function---real and simulated---are almost always critically limited by the number of stimuli that can be considered. 
In some early stages of sensory processing, a combination of intuition and systems identification theory has led to reasonable models of early neuron response functions (e.g. Gabor wavelet models in cortical area V1), but cascading nonlinearities have tended to foil our best efforts in later stages of sensory processing.

Here, we propose a closed-loop experimental framework for characterizing the response properties of sensory neurons, building on past efforts in closed-loop experimental methods, and leveraging recent advances in artificial neural network models to serve as as a proving ground for our techniques.
To the extent that modern deep learning models increasingly serve as \emph{de facto} working hypotheses for biological vision \ref{jim, others}, we argue that a unified approach of developing methods to interrogate 