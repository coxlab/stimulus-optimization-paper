%why depth? bad about universal approx theorem? 
%L2 distance vs. cosine distance? 
%v1, poor selectivity, large size?

\subsection*{Why Do We Need a New Framework?} % NOVELTY OF METHODS

As aforementioned, the study of sensory representations of biological neural networks has been an extremely important research topic for decades and numerous methods have been proposed; nevertheless, most methods can be viewed as implementation instances of functional frameworks of certain generalized concepts \cite{wu2006complete, dimattina2013adaptive}. We argue than existing frameworks being actively used are still mostly highly parametric, in terms of both the model assumption and stimulus generation. As moving away from peripheral or primary sensory circuitry and going deeper into higher-level sensory cortices, the modeling power of parametric models becomes inevitably insufficient, and even though parametric stimulus may facilitate the speed of representation characterization, its inherently assumptive nature can strongly bias the results. Although there also exist approaches which utilize the nonparametric artificial neural networks as models of sensory circuitry, only usage of shallow networks has been reported \cite{lau2002computational, prenger2004nonlinear}, and interpreting the resultant model remains difficult and largely approximate \cite{wu2006complete}. In fact, this also directly links to the fact that attempts of characterizing/interpreting artificial neural networks themselves are also relatively difficult and scarce, and sometimes algorithms using handcrafted representations (e.g.~HoG and SIFT \cite{szeliski2010computer}) are still preferred for their interpretability. Such problems only get worse when deeper networks are being adopted (either as system identification models of biological circuitry, or as algorithms directly applied in tasks), since understanding them also becomes even harder. Another important issue is the lack of principled and efficient approach for characterizing neuronal populations, due to the fact that, e.g., there is no straightforward generalization of the definition of optimal stimulus to neural populations, and existing methods can suffer from the exponential growth of required measurements, with respect to the population size \cite{dimattina2013adaptive}.

Major benefits of the proposed framework can be categorized as follows. (1) Generality: as aforementioned, the proposed framework tackles the challenges in studying sensory representation in a highly generalizable and unbiased way via supporting both nonparametric models and nonparametric stimuli. Although not explicitly tested in this work, such setting in practice can be easily reconfigured and extended, if desired, to support both parametric models, by numerically analyzing them as nonparametric models (especially when analytical solutions are not easily derivable), and parametric stimuli, by simply reframing the optimization in the parameter space $p \in \mathbb{R}^P$ and evaluating the fitness through the generative function $f\left(x\left(p\right)\right)$ (especially when certain stimulus type or deformation is confirmed to be highly relevant). Also, the proposed framework supports characterizing both unit and population representations, as described in \nameref{sec:methods}; the fitness-distance diagram can be viewed as a ``generalized tuning curve'' characterization of the landscape, which is also dimensionality- and population size-insensitive. (2) Efficiency: the proposed framework is designed to be efficient using low-rank and stochastic approximations of the complex high-dimensional tuning landscape and its properties. As reported in multiple existing works \cite{touryan2002isolation, rust2004spike} which utilized second-order model for system identification and representation characterization, often only eigenvectors corresponding to few of the most positive and negative eigenvalues have significant and interpretable structures. Directly searching for invariance and selectivity paths eases this problem and saves potentially costly measurement requirement, which is on the order of $\mathcal{O}\left(N^2\right)$, to $\mathcal{O}\left(N\right)$, in addition to the fact that non-local characterization can be obtained in this work as well. Stochastic sampling of the solution space of the invariance subspace capacity provides an efficient approximation of the intrinsic dimension estimation approach \cite{kegl2002intrinsic, levina2004maximum}, and, of the encoding specificity, an efficient alternative of the maximally informative ensemble estimation approach \cite{machens2002adaptive}, both of which can require substantially more measurements in order to yield robust and meaningful results. As aforementioned, the back-end solver with relatively simple constraints also positively contributes to the speed of this framework. %sharpee2004analyzing

\subsection*{How Close Are We to Fully Understanding Deep Networks?} % CONTRIBUTION/MEANING OF FINDINGS, REPRESENTATION-WISE

Via the proposed numerical optimization framework, the following important aspects of sensory representation research are enabled or facilitated: (1) Decoding unit or population representation (as optimal or reconstructed stimulus). (2) Discovering what changes in stimulus the representation is invariant or selective to. (3) Explaining how deep network's representation may affect its task performances. Main findings of this work can be summarized as:
\begin{itemize} % Main Findings
\item Complexity of representation increases along network's depth.
\item Unlike deep representation which is both invariant and selective, shallow representation is only invariant, not selective, and its capacity of invariance is significantly lower than deep representation's.
\item How well the optimal stimulus can explain task-related stimuli, and how specific the representation encoding of task-related stimuli is, both decently explain network's task performance.
\item How well the invariance and selectivity of representation align with the actual ``distribution'' of task-related stimuli also partially explains network's task performance.
\end{itemize}
We argue the importance of these findings as follows. First, the experiments are conducted in large scale and all results are statistically significant. Second, the results are obtained with relatively unbiased methods (i.e.~nonparametric model plus nonparametric stimulus). Third, the representation measures match what are known to be crucial properties of performing accurate visual recognition, and explain network's performance decently. Finally, the results also point out the practicability of the relatively less explored paradigm, where not only population representation can be examined, but extrinsic properties (i.e.~measures based on task-related stimuli) also can be integrated to more effectively characterize various aspects of the deep network, in addition to only using intrinsic properties (i.e.~measures based on optimal stimuli). In fact, if just using the four intrinsic properties (i.e. OSSC, INPP, SLPP and INSC as shown in Fig.~\ref{fig:ind_mea}; not included in Fig.~\ref{fig:all_R^2}) of the unit representations of the deep networks (with measures averaged from all 32 top-layer neurons within a network), we can only explain the network's performance with $R^2 = 0.34$, which is significantly lower than the correlation based on extrinsic properties (i.e.~$R^2 = 0.71$; combining both properties only marginally increase $R^2$ to 0.73). This also corresponds to our observation that the ranking of deep networks may differ from task to task (e.g.~face pair matching in this work vs.~object recognition in \cite{pinto2009high}), and the fact that neural circuitry can (and maybe constantly) dynamically shape its tuning (i.e.~representation) according to the tasks being performed \cite{gilbert2007brain} such that ``intrinsic'' properties may not mean much. Also, combining the results from machine learning and computer vision studies about deep networks' advanced theoretical efficiency \cite{delalleau2011shallow, montufar2014number} and practical performances over shallow networks', we argue that network depth is possibly the most plausible way of implementing efficient sensory processing.

% finding not just by unit or intrinsic. [intriguing,malik]

However, there are still undeniably plenty of unsolved and even unaddressed mysteries about deep networks. Here we list the ones we think to be of the most importance. First, even though we have successfully visualized the representations of certain deep neurons, as what is argued in \nameref{sec:results} about the optimal construction of tuning landscapes, how these representations explicitly facilitate generalization (i.e.~invariance) across features that are distinct but of the same class, and discrimination (i.e.~selectivity) between features that are similar but of different classes, remains ambiguous. Second, even though some smaller-scale studies using heuristic evaluation \cite{zeiler2014visualizing} or theoretical characterization \cite{saxe2013exact} of representations' evolution have been conducted, how the training algorithms (e.g.~backpropagation) explicitly (and orientedly) shape the representations, and how different training settings alter the resultant representations, remain largely unclear. Third, the ability of ``bottom-up attention'' seems to be prominently functioning in these feedforward deep networks \cite{zeiler2014visualizing, simonyan2013deep} for unaligned and mildly cluttered visual object recognition; even though pooling operations are generally considered capable of providing such function, to what degree it (or other operations) contributes to this, how it explicitly (or implicitly) resolves, e.g., objects' labels from cluttered scenes, and how much variation can be tolerated, remain unclear. Finally, some ``higher-level vision'' tasks also have been reported working decently using deep networks (e.g.~image style recognition \cite{karayev2013recognizing} and scene understanding \cite{CVPR14_Khosla}), in which what might the representations being used are can be even more ambiguous and undefined, and more ``holistic'', instead of part-based, representations, are likely to dominate. As argued in \cite{cox2014we}, object recognition alone is a limited operational definition of high-level vision, and may not even be the right framing problem for studying high-level vision and visual representations any more. Like \cite{olshausen2005close}, we start this subsection by asking how close we are to solving this puzzle, yet with all the remaining inexplicable properties of deep networks, maybe asking how far we are from solving this, and how to precisely address these mysteries, would be more important and fruitful questions to be asked.

\subsection*{Challenges and Possible Directions}

In addition to the inexplicable properties of deep networks listed above, which still lack clearer definitions and directions, here in the following, with no specific order, we also give a list of more defined challenges that we will need to solve, and possible directions to specifically tackle the challenges. Arguably, sensory representations of the most interest are at neither the bottom layer nor the top layer, but intermediate layers, since the former is relatively well understood and usually consist of Gabor (or Gabor-like) filters, and the later is highly class selective, as directly suggested by the ``behavioral'' (i.e.~classification) results and the visualizations shown in \cite{donahue2014decaf, azizpour2014generic}. However, for most advanced deep networks \cite{szegedy2014going, simonyan2014very} which can have around 20 layers of operations, even intermediate layers can be very computationally expensive to measure and may have way more complex tuning landscapes (compared to the two-level deep networks experimented in this work, which consist of up to 8 layers of operations). Instead of CPU-based deep network simulation adopted in this work, GPU- or FPGA-/ASIC-based simulation may be required to tackle the potential speed problem. The back-end numerical solver used in this work may not suffice the needs for even deeper networks either; nevertheless, the proposed framework itself is neutral to the selection of solvers, thus more advanced numerical optimization algorithms can always be adopted to improve the quality of numerical solutions. Similar challenges may be encountered when moving from purely feedforward architectures into more biologically plausible ones---networks with feedback pathways, or recurrent networks---for their widely known nature of complex dynamics. Though in this work, around 70\% of the variance of performance differences on face pair matching can be explained with the proposed representation measures, yet we are not clear how high this number can be driven, and if these measures can generalize well enough onto even deeper representations or radically different types of tasks (e.g.~phoneme recognition). Therefore, the validation/search of existing/new representation measures shall still be an urgent direction for future research. 

Another difficult yet potentially fruitful future challenge is to apply this framework to real biological deep networks. While results are exclusively shown for artificial networks, the methods presented in this work by nature require a small budget of neuronal measurements that they could potentially be applied to real neurons in real experiments, even when spiking variability is taken into account, given that at least two effective techniques---stochastic averaging and measurement reweighting---are built in the core of CMA-ES, the back-end solver, for robustness against measurement noises. In fact, we argue that the mathematical formulation of CMA-ES can be viewed as an extension/generalization of the spike-trigger covariance method, which is known to be working effectively for biological neurons \cite{rust2004spike}. Potential inefficiency of measurement arising from neural adaptation \cite{kohn2007visual} can also benefit from, e.g., Particle Swarm CMA-ES \cite{muller2009particle} or other multipopulation/multimodal optimization methods, where evaluation of stimuli from different local searches can be interwoven to minimize neural adaption and maintain search speed. Overall, as aforementioned, since the proposed framework supports efficient nonparametric search and analysis, a biological neural network can be characterized \emph{as is} to reduce the chances of obtaining premature or biased numerical results. On the other hand, based upon recently reported results of deep networks being able to produce representations similar to mammalian visual systems' \cite{yamins2014performance, cadieu2014deep}, which though may still seem incomplete, we argue that the possibility of deep networks being a good surrogate model for understanding biologically plausible ways of representation encoding, and even guiding the research direction of ventral visual pathway studies, should not be neglected. In addition to the tools proposed in this work, neurophysiological methods like patch clamping, lesioning, ``gene'' (i.e.~hyperparameters) knockout/knockdown, etc.~may be as well used to inspire the development of new tools for characterizing artificial deep networks. For instance, the effect of surround suppression is also observed in experimented artificial neurons in this work as visualized in Fig.~\ref{fig:ind_res} (i.e.~flat gray peripheries in the optimal stimulus patterns; responses drop when manually place, e.g., dots in peripheries) and, in our preliminary tests, can be easily shutdown via ``lesioning'' the prenormalization operations (i.e.~early-stage lateral inhibition) of the network, which is consistent with neurophysiological findings \cite{cavanaugh2002selectivity}.

Finally, though via the proposed numerical framework, we have demonstrated how previously unknown or unconfirmed properties can be positively identified with high statistical significance, we know this does not entirely cover what will be needed to ``fully'' explain observed properties and ultimately everything about sensory representations within deep networks---a theoretical framework yet to be constructed/completed. Notable recent works on bottom-up construction of theoretical frameworks for feedforward convolutional deep networks include magic theory \cite{anselmi2013unsupervised}, scattering transform \cite{mallat2012group}, convolutional kernel network \cite{MairalKHS14}, etc. Saxe et al.~\cite{saxe2011random} and Szegedy et al.~\cite{szegedy2013intriguing} also addressed particular phenomena observed in deep networks using top-down theoretical approaches, furthermore to the theoretical studies \cite{delalleau2011shallow, montufar2014number} on deep network's properties mentioned above. While undoubtedly all different theoretical approaches should keep being actively researched and interactively inspired by each other, we argue that the proposed numerical framework can nicely function as an independent \emph{diagnostic tool} for examining, verifying, and facilitating the construction of theories.

